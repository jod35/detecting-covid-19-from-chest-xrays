{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a deep learning network we are mindful about:\n",
    "1. Data\n",
    "2. Scoring function\n",
    "3. Loss function\n",
    "4. Weights and bias\n",
    "\n",
    "Gradient Descent is attempting to optimize our parameters for low loss and high classification accuracy via an iterative process of taking a step  in the direction that minimizes the loss. Learning rate is one of the two hyper parameters that is set for finding the optimal convergence. The other parameter defined later is the regularization penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 5\n",
    "BS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "label covid on image dataset/dataset/covid/ryct.2020200034.fig5-day7.jpeg\n",
      "label covid on image dataset/dataset/covid/1-s2.0-S0140673620303706-fx1_lrg.jpg\n",
      "label covid on image dataset/dataset/covid/radiol.2020200490.fig3.jpeg\n",
      "label covid on image dataset/dataset/covid/ryct.2020200034.fig2.jpeg\n",
      "label covid on image dataset/dataset/covid/ryct.2020200034.fig5-day0.jpeg\n",
      "label covid on image dataset/dataset/covid/ryct.2020200028.fig1a.jpeg\n",
      "label covid on image dataset/dataset/covid/1-s2.0-S0929664620300449-gr2_lrg-a.jpg\n",
      "label covid on image dataset/dataset/covid/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n",
      "label covid on image dataset/dataset/covid/1-s2.0-S0929664620300449-gr2_lrg-d.jpg\n",
      "label covid on image dataset/dataset/covid/radiopedia-covid-19-pneumonia-2.jpg\n",
      "label covid on image dataset/dataset/covid/nejmoa2001191_f1-PA.jpeg\n",
      "label covid on image dataset/dataset/covid/nejmoa2001191_f5-PA.jpeg\n",
      "label covid on image dataset/dataset/covid/lancet-case2b.jpg\n",
      "label covid on image dataset/dataset/covid/nejmc2001573_f1b.jpeg\n",
      "label covid on image dataset/dataset/covid/nCoV-radiol.2020200269.fig1-day7.jpeg\n",
      "label covid on image dataset/dataset/covid/lancet-case2a.jpg\n",
      "label covid on image dataset/dataset/covid/lancet-case2a copy.jpg\n",
      "label covid on image dataset/dataset/covid/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n",
      "label covid on image dataset/dataset/covid/nejmoa2001191_f3-PA.jpeg\n",
      "label covid on image dataset/dataset/covid/1-s2.0-S0929664620300449-gr2_lrg-b.jpg\n",
      "label covid on image dataset/dataset/covid/ryct.2020200034.fig5-day4.jpeg\n",
      "label covid on image dataset/dataset/covid/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n",
      "label covid on image dataset/dataset/covid/1-s2.0-S0929664620300449-gr2_lrg-c.jpg\n",
      "label covid on image dataset/dataset/covid/nejmoa2001191_f4.jpeg\n",
      "label covid on image dataset/dataset/covid/auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg\n",
      "label covid on image dataset/dataset/covid/nejmc2001573_f1a.jpeg\n",
      "label normal on image dataset/dataset/normal/person651_bacteria_2543.jpeg\n",
      "label normal on image dataset/dataset/normal/person1599_virus_2776.jpeg\n",
      "label normal on image dataset/dataset/normal/person925_virus_1582.jpeg\n",
      "label normal on image dataset/dataset/normal/person1290_virus_2215.jpeg\n",
      "label normal on image dataset/dataset/normal/person339_bacteria_1574.jpeg\n",
      "label normal on image dataset/dataset/normal/NORMAL2-IM-0315-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/NORMAL2-IM-0869-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/IM-0466-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/NORMAL2-IM-0696-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/person438_bacteria_1893.jpeg\n",
      "label normal on image dataset/dataset/normal/person989_virus_1667.jpeg\n",
      "label normal on image dataset/dataset/normal/person378_virus_761.jpeg\n",
      "label normal on image dataset/dataset/normal/person1_bacteria_2.jpeg\n",
      "label normal on image dataset/dataset/normal/person1558_bacteria_4066.jpeg\n",
      "label normal on image dataset/dataset/normal/IM-0033-0001-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/person1935_bacteria_4849.jpeg\n",
      "label normal on image dataset/dataset/normal/person612_bacteria_2478.jpeg\n",
      "label normal on image dataset/dataset/normal/NORMAL2-IM-1179-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/IM-0240-0001.jpeg\n",
      "label normal on image dataset/dataset/normal/person1102_bacteria_3043.jpeg\n",
      "label normal on image dataset/dataset/normal/person939_bacteria_2864.jpeg\n",
      "label normal on image dataset/dataset/normal/person525_bacteria_2216.jpeg\n",
      "label normal on image dataset/dataset/normal/person259_bacteria_1220.jpeg\n",
      "label normal on image dataset/dataset/normal/person1830_bacteria_4693.jpeg\n",
      "label normal on image dataset/dataset/normal/person934_virus_1595.jpeg\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    \n",
    "    print(f\"label {label} on image {imagePath}\")\n",
    "\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224)) # Explain why 224 and not Dr Cohen's 227px\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "    \n",
    "\n",
    "# convert the data and labels to NumPy arrays while scaling the pixel\n",
    "# intensities to the range [0, 1]\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "# Each encoded label consists of a two element array with one of the elements being \n",
    "# “hot” (i.e., 1) versus “not” (i.e., 0).\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the word “augment” means to make something “greater” or “increase” something (in this case, data), the Keras ImageDataGenerator class actually works by:\n",
    "\n",
    "Accepting a batch of images used for training.\n",
    "Taking this batch and applying a series of random transformations to each image in the batch (including random rotation, resizing, shearing, etc.).\n",
    "Replacing the original batch with the new, randomly transformed batch.\n",
    "Training the CNN on this randomly transformed batch (i.e., the original data itself is not used for training).\n",
    "The Keras ImageDataGenerator class is not an “additive” operation. It’s not taking the original data, randomly transforming it, and then returning both the original data and transformed data.\n",
    "\n",
    "Instead, the ImageDataGenerator accepts the original data, randomly transforms it, and returns only the new, transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jod35/anaconda3/envs/tensorflow-env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization penalty - Data Augmentation - efforts to reduce test error at expense of increased training error (overfitting). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/jod35/anaconda3/envs/tensorflow-env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "5/5 [==============================] - 524s 105s/step - loss: 0.5650 - acc: 0.7500 - val_loss: 0.6417 - val_acc: 0.5455\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 528s 106s/step - loss: 0.9378 - acc: 0.4500 - val_loss: 0.6544 - val_acc: 0.5455\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 558s 112s/step - loss: 0.8408 - acc: 0.5500 - val_loss: 0.6131 - val_acc: 0.5455\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 514s 103s/step - loss: 0.8804 - acc: 0.5000 - val_loss: 0.6087 - val_acc: 0.9091\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 555s 111s/step - loss: 0.7498 - acc: 0.6250 - val_loss: 0.5998 - val_acc: 0.9091\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       1.00      0.83      0.91         6\n",
      "      normal       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.92      0.92      0.91        11\n",
      "weighted avg       0.92      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pattern recognition, information retrieval and classification (machine learning), precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved.\n",
    "\n",
    "As you can see from the results above, our automatic COVID-19 detector is obtaining ~91-92% \n",
    "accuracy on our sample dataset based solely on X-ray images — no other data, \n",
    "including Non-identifying demographics, such as age, sex, ethnicity; History of present illness, including exposure/travel and symptom history; Medical history, including major comorbidities and frailty assessment; Clinical / nursing observations, such as vital signs; All laboratory tests performed etc. was used to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix and and use it to derive the raw\n",
    "# accuracy, sensitivity, and specificity\n",
    "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1]\n",
      " [0 5]]\n",
      "acc: 0.9091\n",
      "sensitivity: 0.8333\n",
      "specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "print(cm)\n",
    "print(\"acc: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also obtaining 100% sensitivity and 80% specificity implying that:\n",
    "\n",
    "1. Of patients that do have COVID-19 (i.e., true positives), we could accurately identify them \n",
    "as “COVID-19 positive” 100% of the time using our model.\n",
    "2. Of patients that do not have COVID-19 (i.e., true negatives), we could accurately identify them \n",
    "as “COVID-19 negative” only 80% of the time using our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to accurately detect COVID-19 with 100% accuracy is great; however, our true negative rate is a bit concerning — we don’t want to classify someone as “COVID-19 negative” when they are “COVID-19 positive”.\n",
    "\n",
    "In fact, the last thing we want to do is tell a patient they are COVID-19 negative, and then have them go home and infect their family and friends; thereby transmitting the disease further.\n",
    "\n",
    "We also want to be really careful with our false positive rate — we don’t want to mistakenly classify someone as “COVID-19 positive”, quarantine them with other COVID-19 positive patients, and then infect a person who never actually had the virus.\n",
    "\n",
    "Balancing sensitivity and specificity is incredibly challenging when it comes to medical applications, especially infectious diseases that can be rapidly transmitted, such as COVID-19.\n",
    "\n",
    "When it comes to medical computer vision and deep learning, we must always be mindful of the fact that our predictive models can have very real consequences — a missed diagnosis can cost lives.\n",
    "\n",
    "Again, these results are gathered for proof of concept only. The accompanying results dont conform to the TRIPOD guidelines on reporting predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a49a39f77ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss and Accuracy on COVID-19 Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plots_5eps.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our training history plot shows, our network is not overfitting, despite having very limited training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving COVID-19 detector model...\n"
     ]
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving COVID-19 detector model...\")\n",
    "model.save('covid-19-model-5eps', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations, improvements, and future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We simply don’t have enough (reliable) data to train a COVID-19 detector.\n",
    "\n",
    "Hospitals are already overwhelmed with the number of COVID-19 cases, and given patients rights and confidentiality, it becomes even harder to assemble quality medical image datasets in a timely fashion.\n",
    "\n",
    "We imagine in the next 12-18 months we’ll have more high quality (age,sex,race,co-morbidity (underlying illness))COVID-19 image datasets; but for the time being, we can only make do with what we have.\n",
    "\n",
    "For the COVID-19 detector to be deployed in the field, it would have to go through rigorous testing by trained medical professionals, working hand-in-hand with expert deep learning practitioners. The method covered here today is certainly in that direction, but is meant for proof of concept purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Furthermore, we need to be concerned with what the model is actually “learning”.\n",
    "\n",
    "It’s possible that our model is learning patterns that are not relevant to COVID-19, and instead are just variations between the two data splits (i.e., positive versus negative COVID-19 diagnosis).\n",
    "\n",
    "It will take medical professionals and rigorous testing to validate the results coming out of our COVID-19 detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "network=load_model('covid-19-model-5eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "\n",
    "img=load_img(\n",
    "    'covid.jpeg',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "# Explain why 224 and not Dr Cohen's 227px\n",
    "\n",
    "img_array=img_to_array(img)\n",
    "\n",
    "img_array=tf.expand_dims(img_array,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.predict(img_array,steps=1)\n",
    "score = tf.nn.softmax(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01455611 0.9854439 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'normal'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['covid','normal']\n",
    "\n",
    "class_names[np.argmax(predictions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
